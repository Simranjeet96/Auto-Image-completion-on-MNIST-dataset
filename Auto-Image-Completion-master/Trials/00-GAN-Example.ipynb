{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2219b971f98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0w55Wdgs4pYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2219b59dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[11].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
      "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, shape=(1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.ones(shape=[28,28], dtype=np.float32)\n",
    "mask[10:18,10:18] = 0\n",
    "mask = mask.reshape(1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_to_correct = tf.multiply(tf.reshape(img, shape=(28,28)), tf.convert_to_tensor(tf.reshape(mask, shape=(28,28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z1 = tf.Variable(initial_value = np.random.uniform(-1, 1, size=(1, 100)).astype(\"float32\"), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1 = generator(z1, reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_gen_masked = tf.multiply(G1, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contextual_loss = tf.reduce_mean(tf.abs(img_gen_masked - tf.reshape(img_to_correct,shape=(1,784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_loss = (1- discriminator(G1,reuse=True)[0])\n",
    "# perceptual_loss=G_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_loss = contextual_loss + 0.0*perceptual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_loss_trainer = tf.train.AdamOptimizer(learning_rate).minimize(complete_loss, var_list=z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Session"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "batch_size = 500\n",
    "epochs = 100\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a sample per epoch\n",
    "samples = []\n",
    "ans_z = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "\n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # // indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "    saver.save(sess, '../models/100_epoch_model.ckpt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'../models1/500_epoch_model.ckpt')\n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # // indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "    saver.save(sess, '../models/100_epoch_model1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models1/500_epoch_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'../models1/500_epoch_model.ckpt')\n",
    "    for i in range(1000):\n",
    "        _ = sess.run(complete_loss_trainer, feed_dict = {img: mnist.train.images[91].reshape(1, 784)})\n",
    "        \n",
    "    ansz = sess.run(z1)\n",
    "    gen_ans = sess.run(generator(z ,reuse=True),feed_dict={z: ansz})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2219dc27f98>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICnCDyRF+IGkCD+QFOEHkvo/c9UpSMSMAQAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2219da629e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(gen_ans.reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
