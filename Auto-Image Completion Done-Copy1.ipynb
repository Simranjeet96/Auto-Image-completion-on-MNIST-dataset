{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18bd5ff9128>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18bd5eeecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[76].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = generator(z,reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images,reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
      "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a sample per epoch\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # // indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "        saver.save(sess, './models/500_epoch_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, shape=(1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.ones(shape=[28,28], dtype=np.float32)\n",
    "mask[10:15,10:15] = 0\n",
    "mask = mask.reshape(1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_to_correct = tf.multiply(tf.reshape(img, shape=(28,28)), tf.convert_to_tensor(tf.reshape(mask, shape=(28,28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zhat = tf.Variable(initial_value = np.random.uniform(-1, 1, size=(1, 100)).astype(\"float32\"), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1=generator(zhat,reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_gen_masked = tf.multiply(tf.reshape(G1, shape=(28,28)), tf.convert_to_tensor(tf.reshape(mask, shape=(28,28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contextual_loss = tf.reduce_sum(tf.abs(img_gen_masked - img_to_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perceptual_loss = G_loss\n",
    "perceptual_loss=(1- discriminator(G1,reuse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_loss = 12**contextual_loss + perceptual_loss**14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_loss_trainer = tf.train.AdamOptimizer(learning_rate).minimize(complete_loss,var_list=zhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x = np.random.rand(100)*10\n",
    "\n",
    "norm = normalize(x[:,np.newaxis], axis=0).ravel()\n",
    "\n",
    "print(x)\n",
    "print('\\n')\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18bd72e72e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaQIP5AU4QeSIvxAUoQfSOr/ARf0AXTaxpBkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18bd6f875c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[25].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models1/500_epoch_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import normalize\n",
    "# saver = tf.train.Saver()\n",
    "v = 0\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess,'./models1/500_epoch_model.ckpt')\n",
    "    \n",
    "    \n",
    "    for x in range(1000):\n",
    "        run = [complete_loss_trainer,zhat]\n",
    "        _,yeeee = sess.run(run, feed_dict = {img: mnist.train.images[25].reshape(1, 784)})\n",
    "        \n",
    "    image_generated=sess.run(generator(zhat,reuse=True),feed_dict={zhat:yeeee})\n",
    "#         zhat = normalize(zhat[:], axis=1).ravel()\n",
    "#         zhat = zhat.reshape(1, 100)\n",
    "#         zhat = np.clip(zhat, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18bd78feba8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simra\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py:823: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "C:\\Users\\simra\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py:2766: UserWarning: Warning: converting a masked element to nan.\n",
      "  order=order, subok=True, ndmin=ndmin)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npoxfasr4paaMX2rK+KWm/h9AyFgFyzVQIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18bd734eba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_generated.reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
